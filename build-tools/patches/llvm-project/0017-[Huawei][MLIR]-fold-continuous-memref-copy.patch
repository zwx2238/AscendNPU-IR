diff --git a/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp b/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp
index f8d5d8b86f93..8753d26d9bd1 100644
--- a/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp
+++ b/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp
@@ -834,6 +834,137 @@ struct FoldSelfCopy : public OpRewritePattern<CopyOp> {
   }
 };
 
+#if BSPUB_DAVINCI_BISHENGIR
+
+/// 1. fold `copy A B; copy B C` to `copy A C`
+/// 2. fold `copy A B; B0 = reshape(B); copy B0 C`
+///    to   `A0 = reshape(A); copy A0 C;`
+///    if `B` only has one user `B0 = reshape(B)`
+struct FoldRedundantCopy : public OpRewritePattern<memref::CopyOp> {
+  using OpRewritePattern<memref::CopyOp>::OpRewritePattern;
+
+  LogicalResult matchAndRewrite(memref::CopyOp copyOp,
+                                PatternRewriter &rewriter) const override {
+    Value src = copyOp.getSource();
+    Value dst = copyOp.getTarget();
+    if (src == dst)
+      return failure();
+
+    SmallVector<Operation *> reshapeTrace;
+    auto copyMaybe = traceSingleReshapeUtilCopy(dst, copyOp, reshapeTrace);
+    if (!copyMaybe.has_value()) {
+      // avoid fold `copy A B; not_reshape_use(B); copy B C` to `copy A C`
+      return failure();
+    }
+
+    memref::CopyOp copyFromDst = copyMaybe.value();
+    if (!copyOp->isBeforeInBlock(copyFromDst)) {
+      // avoid fold `copy B C; copy A B` to `copy A C`, wrong order
+      return failure();
+    }
+
+    DenseSet<Operation *> skipCopyOps{copyOp, copyFromDst};
+    if (!isUsersMemoryEffectFree(src, skipCopyOps) ||
+        !isUsersMemoryEffectFree(copyFromDst.getTarget(), skipCopyOps)) {
+      // 1. avoid fold `copy A B; memory_effect(A); copy B C` to `copy A C`
+      // 2. avoid fold `copy A B; memory_effect(C); copy B C` to `copy A C`
+      return failure();
+    }
+
+    // create new copy source following the reshape trace on old copy source
+    Value reshapeFromSrc = src;
+    Location loc = copyOp.getLoc();
+    for (Operation *op : reshapeTrace) {
+      if (auto collapse = dyn_cast<memref::CollapseShapeOp>(op)) {
+        reshapeFromSrc = rewriter.create<memref::CollapseShapeOp>(
+            loc, reshapeFromSrc, collapse.getReassociationIndices());
+        continue;
+      }
+      if (auto expand = dyn_cast<memref::ExpandShapeOp>(op)) {
+        reshapeFromSrc = rewriter.create<memref::ExpandShapeOp>(
+            loc, expand.getResultType(), reshapeFromSrc,
+            expand.getReassociationIndices());
+        continue;
+      }
+      llvm_unreachable("invalid reshape op");
+    }
+
+    rewriter.setInsertionPointAfter(copyFromDst);
+    rewriter.create<memref::CopyOp>(copyFromDst.getLoc(), reshapeFromSrc,
+                                    copyFromDst.getTarget());
+
+    rewriter.eraseOp(copyOp);
+    rewriter.eraseOp(copyFromDst);
+    return success();
+  }
+
+  bool isUsersMemoryEffectFree(Value src,
+                               const DenseSet<Operation *> &skipCopyOps) const {
+    return llvm::all_of(src.getUsers(), [&](Operation *user) {
+      if (skipCopyOps.contains(user)) {
+        return true;
+      }
+      if (isMemoryEffectFree(user)) {
+        return true;
+      }
+      // make sure all op with memory effect exist before or after skipCopyOps
+      bool userBeforeAll = llvm::all_of(skipCopyOps, [&](Operation *skipOp) {
+        return user->isBeforeInBlock(skipOp);
+      });
+      bool userAfterAll = llvm::all_of(skipCopyOps, [&](Operation *skipOp) {
+        return skipOp->isBeforeInBlock(user);
+      });
+      return userBeforeAll || userAfterAll;
+    });
+  }
+
+  // Returns the single user of src except for `skipOp`
+  // If there are more than one users except for `skipOp`, return nullptr
+  Operation *getSingleUser(Value src, Operation *skipOp) const {
+    Operation *user = nullptr;
+    for (OpOperand &use : src.getUses()) {
+      Operation *curUser = use.getOwner();
+      if (curUser == skipOp) {
+        // skip the origin user to avoid confusion
+        continue;
+      }
+      if (user != nullptr) {
+        // there should be only one user other than the origin user
+        return nullptr;
+      }
+      user = curUser;
+    }
+    return user;
+  }
+
+  // Trace reshape op starting from src, util find a interested memref::CopyOp.
+  // If there are multiple users along the way, or no target copy, or other op
+  // type other than reshape/copy, return nullptr
+  std::optional<memref::CopyOp>
+  traceSingleReshapeUtilCopy(Value src, Operation *skipOp,
+                             SmallVector<Operation *> &useChain) const {
+    Operation *user = getSingleUser(src, skipOp);
+    if (user == nullptr) {
+      // no fold is needed if there is no other users
+      return std::nullopt;
+    }
+
+    if (isa<memref::CollapseShapeOp>(user) ||
+        isa<memref::ExpandShapeOp>(user)) {
+      useChain.push_back(user);
+      return traceSingleReshapeUtilCopy(user->getResult(0), user, useChain);
+    }
+    if (auto copyOp = dyn_cast<memref::CopyOp>(user)) {
+      if (copyOp.getSource() == src && copyOp.getTarget() != src) {
+        // only allow copy from src to other dst
+        return copyOp;
+      }
+    }
+    return std::nullopt;
+  }
+};
+#endif
+
 struct FoldEmptyCopy final : public OpRewritePattern<CopyOp> {
   using OpRewritePattern<CopyOp>::OpRewritePattern;
 
@@ -857,6 +988,9 @@ struct FoldEmptyCopy final : public OpRewritePattern<CopyOp> {
 
 void CopyOp::getCanonicalizationPatterns(RewritePatternSet &results,
                                          MLIRContext *context) {
+#if BSPUB_DAVINCI_BISHENGIR
+  results.add<FoldRedundantCopy>(context);
+#endif
   results.add<FoldCopyOfCast, FoldEmptyCopy, FoldSelfCopy>(context);
 }
 
